{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is all the scripts I have written for lab that I found useful along with a description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The 6 cells below is my creation of a datafrfame that filter for specific fasstas from a larger fasta, \n",
    "#mainly used for between species analysis of coding and noncoding regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'af293 a1163 oerlinghausenensis fischeri lentulus fumigatiaffinis novofumigatus udagawae thermomutatus turcosus'.split()\n",
    "df_final = pd.DataFrame(columns= column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_name = '/Users/alecbrown/Desktop/Rokas_Lab/Genomes_paper_1/excel_sheets/single_copy_genes.xlsx'\n",
    "df = pd.read_excel(excel_name, dtype=str, na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cds_fasta = '/Users/alecbrown/Desktop/Rokas_Lab/Genomes_paper_1/FILES_intergenic/500_bp/turcosus_intergenic_500.txt'\n",
    "inFile = open(cds_fasta,'r') \n",
    "\n",
    "headerList = []\n",
    "seqList = []\n",
    "currentSeq = 'placeholder' #place holder skips the first currentseq from being ''\n",
    "for line in inFile:\n",
    "    if line[0] == \">\":\n",
    "        headerList.append(line[1:].strip())\n",
    "        if currentSeq != 'placeholder':\n",
    "            seqList.append(currentSeq)\n",
    "   \n",
    "        currentSeq = ''\n",
    "        \n",
    "    else:\n",
    "        currentSeq += line.strip()\n",
    "\n",
    "   \n",
    "seqList.append(currentSeq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchfor_list = []\n",
    "for value in df['turcosus']: #This will be specific for df column that contains gene IDs of interest\n",
    "    searchfor_list.append(value) #creates list\n",
    "    \n",
    "new_searchfor_list = []\n",
    "for item in searchfor_list: \n",
    "    new_searchfor_list.append(item.split(','))\n",
    "    \n",
    "combined_list = []\n",
    "for i in range(len(headerList)): \n",
    "    combined_list.append(headerList[i] +'?'+seqList[i]) #This line can be mod to have seperator between id and seq, maybe '?'\n",
    "    #keep in mind, this will have > and \\n for LF when written to txt file\n",
    "combined_list_Series = pd.Series(combined_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_filter_list = []\n",
    "\n",
    "for value in new_searchfor_list:\n",
    "    working_list = []\n",
    "    for items in value: \n",
    "        y = list(filter(lambda x:items in x, combined_list_Series))\n",
    "        if items == '':\n",
    "            working_list.append('')\n",
    "        elif y: \n",
    "            working_list.append(y[0])\n",
    "            \n",
    "    new_filter_list.append(working_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['turcosus'] = new_filter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following 4 cells takes an excel sheet from above (from dataframe) and writes a fasta file for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('/Users/alecbrown/Desktop/Rokas_Lab/Genomes_paper_1/excel_sheets/fasta_500bp.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('orthogroup', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(r'\\?','\\n', regex=True)\n",
    "df = df.replace(r'\\[','', regex=True)\n",
    "df = df.replace(r'\\]','', regex=True)\n",
    "df = df.replace(r\"\\'\",\"\", regex=True)\n",
    "df = df.replace(r'\\\"','', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/alecbrown/Desktop/Rokas_Lab/Genomes_paper_1/fasta/upstream_nt_500bp/')\n",
    "\n",
    "i = 0\n",
    "\n",
    "while i < len(df):\n",
    "    #f = open('testing.txt_'.format(i), 'w')\n",
    "    for row in df[i:1+i].values:\n",
    "        f = open(str(i) + '_upstream.txt', 'w')\n",
    "        for fasta in row:\n",
    "            if fasta.rstrip() == '': #this will skip any empty values\n",
    "                continue\n",
    "            else:\n",
    "                f.write('>' + fasta)\n",
    "                f.write('\\n')\n",
    "    #f.close()\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a general script of using regex to to find a pattewrn in. a larger string, and match strings to that pattern\n",
    "\n",
    "af293_reformat = [] #doesn't have to be appended to a list\n",
    "\n",
    "for i in af293_from_df:\n",
    "    pattern = re.compile(r'E[A-Z0-9.]+')\n",
    "    matches = pattern.finditer(i)\n",
    "                         \n",
    "    for match in matches:\n",
    "        af293_reformat.append(match.group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script to calculate percent similarity given a directory of fasta files, from af293_a1163_9_9_20\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "import re\n",
    "\n",
    "def percent_similarities(path):\n",
    "    \n",
    "    os.chdir(path)\n",
    "    \n",
    "    column = 'Gene_name af293:a1163'.split()\n",
    "    df = pd.DataFrame(columns=column)\n",
    "\n",
    "    for fasta in os.listdir(path):\n",
    "        if 'upstream.txt' in str(fasta):\n",
    "            file = str(fasta)\n",
    "            #print(file)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "        percentages = []\n",
    "        seqs = []\n",
    "        score = None\n",
    "        total_len = None\n",
    "\n",
    "        with open(file, 'r') as f:\n",
    "            for line in f:\n",
    "                if '>' in line and 'EDP' in line:\n",
    "                    continue \n",
    "                if '>' in line and 'AFUA_' in line:\n",
    "                    pattern = re.compile(r'Name=AFUA_[0-9A-Z.]+')\n",
    "                    matches = pattern.finditer(line)\n",
    "                    \n",
    "                    for match in matches:\n",
    "                        percentages.append(match.group(0)[5:])\n",
    "                if '>' in line:\n",
    "                    continue\n",
    "                else:\n",
    "                    seqs.append(line)\n",
    "        if len(seqs) < 2:\n",
    "            print('PROBLEMMMMMMM with this file')\n",
    "            print(seqs[-1])\n",
    "            continue\n",
    "\n",
    "        for i in range(1, len(seqs)):\n",
    "        #while counter < len(seqs):\n",
    "            a = seqs[0]\n",
    "            b = seqs[i]\n",
    "\n",
    "            pairwise_results = pairwise2.align.globalxx(a, b)\n",
    "            for item in pairwise_results:\n",
    "                score = (item[2])\n",
    "\n",
    "            #print(len(a))\n",
    "            #print(len(b))\n",
    "            #print(a)\n",
    "            if len(a) >= len(b):\n",
    "                total_len = len(a)\n",
    "            else:\n",
    "                total_len = len(b)\n",
    "\n",
    "\n",
    "            percentages.append(score/total_len)\n",
    "        df.loc[len(df.index)]=percentages\n",
    "\n",
    "            #counter +=1\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below gets results from a directory with AU_reesults using iqtree as a single dataframe\n",
    "#from AU_test_results_9_28_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_au_results(path, handle):\n",
    "    \n",
    "    os.chdir(path)\n",
    "\n",
    "    dct = {}\n",
    "    for file in os.listdir():\n",
    "        if '.iqtree' not in file:\n",
    "            continue\n",
    "        else:\n",
    "            with open(file, 'r') as f:\n",
    "                s = []\n",
    "                l = []\n",
    "                file_name = str(file)\n",
    "                read = False \n",
    "                for line in f:\n",
    "                    if '-----------------------------------------------------------------' in line:\n",
    "                        read = True\n",
    "                    if ':' in line:\n",
    "                        read = False\n",
    "                    if read == True:\n",
    "                        s.append(line.strip())\n",
    "                    if read == False:\n",
    "                        continue \n",
    "                for i in s[:3]:\n",
    "                    if '--------' in i:\n",
    "                        continue\n",
    "                    if i == '[]':\n",
    "                        continue\n",
    "                    else:\n",
    "                        #print(i)\n",
    "                        values = i.split()\n",
    "                        for items in values:\n",
    "                            if items[0] == '2':\n",
    "                                dct[file_name] = f'{values[-2]}'\n",
    "    #print(dct)\n",
    "    column_names = 'file_name au_result'.split()\n",
    "    df = pd.DataFrame(dct.items(), columns=column_names)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below is a function that will take a dir with codmel results from codeml and generate df with specifics\n",
    "#From Curatrating codeml results files 9_10_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def codeml_null(path):\n",
    "    '''Get information from codeml result files for further LRT test & dn/ds analysis'''\n",
    "    \n",
    "    gene_name_null = []\n",
    "    lnl_null = []\n",
    "    w_null = []\n",
    "    \n",
    "    for filename in os.listdir(path):\n",
    "        if 'result.txt' in filename:\n",
    "            #with open(filename, 'r') as f:\n",
    "            with open(os.path.join(path, filename), 'r') as f:\n",
    "                for line in f:\n",
    "                    if '#1:' in line:\n",
    "                        gene_name_null.append(line[4:-2].strip())\n",
    "                    if 'lnL' in line and 'np: 20' in line:\n",
    "                        #lnl_null.append(line[:-2].strip())\n",
    "                        pattern = re.compile(r'-[0-9.]+')\n",
    "                        matches = pattern.finditer(line)\n",
    "                        \n",
    "                        for match in matches:\n",
    "                            lnl_null.append(match.group(0))\n",
    "                    if 'omega' in line:\n",
    "                        w_null.append(line[:-2].strip())\n",
    " \n",
    "    \n",
    "          \n",
    "    column_names = 'protein_id lnl_null dn/ds_null'.split()\n",
    "    \n",
    "    df = pd.DataFrame(columns=column_names)\n",
    "          \n",
    "    df['protein_id'] = gene_name_null\n",
    "    df['lnl_null'] = lnl_null\n",
    "    df['dn/ds_null'] = w_null\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codeml_alt(path):\n",
    "    '''Get information from codeml result files for further LRT test & dn/ds analysis'''\n",
    "    \n",
    "    gene_name_alt = []\n",
    "    lnl_alt = []\n",
    "    w_alt = []\n",
    "    \n",
    "    for filename in os.listdir(path):\n",
    "        if 'result.txt' in filename:\n",
    "            #with open(filename, 'r') as f:\n",
    "            with open(os.path.join(path, filename), 'r') as f:\n",
    "                for line in f:\n",
    "                    if '#1:' in line:\n",
    "                        gene_name_alt.append(line[4:-2].strip())\n",
    "                    if 'lnL' in line and 'np: 21':\n",
    "                        pattern = re.compile(r'-[0-9.]+')\n",
    "                        matches = pattern.finditer(line)\n",
    "                        \n",
    "                        for match in matches:\n",
    "                            lnl_alt.append(match.group(0)[:-2].strip())\n",
    "                    if '(dN/dS) for branches:' in line:\n",
    "                        w_alt.append(line[:-2].strip())\n",
    " \n",
    "    \n",
    "          \n",
    "    column_names = 'protein_id lnl_alt dn/ds_alt'.split()\n",
    "    \n",
    "    df = pd.DataFrame(columns=column_names)\n",
    "          \n",
    "    df['protein_id'] = gene_name_alt\n",
    "    df['lnl_alt'] = lnl_alt\n",
    "    df['dn/ds_alt'] = w_alt\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The next 3 cells were used to generate dot plots for some RNA seq data from excel data, from figures RNA seq 9_13_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.style.use('seaborn-colorblind')\n",
    "\n",
    "plt.figure(figsize=(16,9), dpi=100)\n",
    "\n",
    "x = df['noncoding']\n",
    "y = df['coding']\n",
    "\n",
    "plt.scatter(x,y, s=50, c='skyblue', edgecolors='black', alpha=0.20)\n",
    "plt.xlabel ('Non-coding region similarity (up to 500bp upstream transcription start site)')\n",
    "plt.ylabel('Coding region similarity (protein sequence)')\n",
    "plt.title('Seqeunce similarity of coding and noncoding regions for single copy orthologous genes. Af293:A1163')\n",
    "\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "\n",
    "#fig1 = plt.gcf()\n",
    "\n",
    "#fig1.savefig('test.png', dpi=100)\n",
    "plt.tight_layout\n",
    "\n",
    "#plt.savefig('af293_a1163_pairwise.png')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graphs(path, t, d): #path=path to RNA seq data, t = title from excel sheet of path, d = original percentages excel sheet\n",
    "    '''Take a previously made scatterplot of id percentage and add a list of data to it, in a new color'''\n",
    "    \n",
    "    df_rnaseq = pd.read_excel(path)\n",
    "    \n",
    "    df_lst = list(df_rnaseq[t].dropna())\n",
    "    \n",
    "    #return(df_lst)\n",
    "    \n",
    "    gene_names = []\n",
    "    for i in df_lst:\n",
    "        gene_names.append(f'AFUA_{i[3:].upper()}')\n",
    "        \n",
    "    #return(gene_names)\n",
    "    \n",
    "    df = pd.read_excel(d)\n",
    "    \n",
    "    dct_coding = dict(zip(df['gene_name'], df['coding']))\n",
    "    dct_noncoding = dict(zip(df['gene_name'], df['noncoding']))\n",
    "    \n",
    "    plt.style.use('seaborn-colorblind')\n",
    "\n",
    "    plt.figure(figsize=(16,9), dpi=100)\n",
    "\n",
    "    x = df['noncoding']\n",
    "    y = df['coding']\n",
    "    \n",
    "    a = []\n",
    "    b = []\n",
    "    \n",
    "    for i in gene_names:\n",
    "        if i in dct_coding.keys():\n",
    "            a.append(dct_coding.get(i))\n",
    "            \n",
    "    for i in gene_names:\n",
    "        if i in dct_noncoding.keys():\n",
    "            b.append(dct_noncoding.get(i))\n",
    "\n",
    "    plt.scatter(x,y, s=50, c='skyblue', edgecolors='black', alpha=0.75, label='Genomic background')\n",
    "    plt.scatter(b,a, s=50, c='orange', edgecolors='black', alpha=1.0, label = 'Differently expressed gene')\n",
    "    plt.xlabel ('Non-coding region similarity')\n",
    "    plt.ylabel('Coding region similarity')\n",
    "    plt.title(f'Seqeunce similarity of coding and noncoding regions for single copy orthologous genes: delta_crza_{t}')\n",
    "\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.legend(loc = 'lower right')\n",
    "\n",
    "    plt.tight_layout\n",
    "\n",
    "    plt.savefig(f'RNA_Seq_delta_crza_{t}.png')\n",
    "    return(plt.show())\n",
    "    #plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, let's compare between wildtype and delta crza based on type\n",
    "#Let's add a legend here as well\n",
    "\n",
    "def compare_graphs(path_wt, path_crza, t, d): #path=path to RNA seq data, t = title from excel sheet of path, d = original percentages excel sheet\n",
    "    '''Take a previously made scatterplot of id percentage and add a list of data to it, in a new color'''\n",
    "    \n",
    "    df_rnaseq = pd.read_excel(path_wt)\n",
    "    df_deltacrza = pd.read_excel(path_crza)\n",
    "    \n",
    "    df_lst = list(df_rnaseq[t].dropna())\n",
    "    df_lst_2 = list(df_deltacrza[t].dropna())\n",
    "    \n",
    "    #return(df_lst)\n",
    "    \n",
    "    gene_names = []\n",
    "    for i in df_lst:\n",
    "        gene_names.append(f'AFUA_{i[3:].upper()}')\n",
    "        \n",
    "    gene_names_delta = []\n",
    "    for i in df_lst_2:\n",
    "        gene_names_delta.append(f'AFUA_{i[3:].upper()}')\n",
    "        \n",
    "    #return(gene_names)\n",
    "    \n",
    "    df = pd.read_excel(d)\n",
    "    \n",
    "    dct_coding = dict(zip(df['gene_name'], df['coding']))\n",
    "    dct_noncoding = dict(zip(df['gene_name'], df['noncoding']))\n",
    "    \n",
    "    plt.style.use('seaborn-colorblind')\n",
    "\n",
    "    plt.figure(figsize=(16,9), dpi=100)\n",
    "\n",
    "    x = df['noncoding']\n",
    "    y = df['coding']\n",
    "    \n",
    "    a = []\n",
    "    b = []\n",
    "    c = []\n",
    "    d = []\n",
    "    \n",
    "    for i in gene_names:\n",
    "        if i in dct_coding.keys():\n",
    "            a.append(dct_coding.get(i))\n",
    "            \n",
    "    for i in gene_names:\n",
    "        if i in dct_noncoding.keys():\n",
    "            b.append(dct_noncoding.get(i))\n",
    "            \n",
    "    for i in gene_names_delta:\n",
    "        if i in dct_noncoding.keys():\n",
    "            c.append(dct_noncoding.get(i))\n",
    "\n",
    "    for i in gene_names_delta:\n",
    "        if i in dct_coding.keys():\n",
    "            d.append(dct_coding.get(i))\n",
    "            \n",
    "    #plt.scatter(x,y, s=50, c='skyblue', edgecolors='black', alpha=0.5)\n",
    "    plt.scatter(b,a, s=50, c='red', edgecolors='black', alpha=0.5, label = 'Wildtype')\n",
    "    plt.scatter(c,d, s=50, c='blue', edgecolors='black', alpha=0.5, label = 'Delta crza')\n",
    "    plt.xlabel ('Non-coding region similarity')\n",
    "    plt.ylabel('Coding region similarity')\n",
    "    plt.title(f'Seqeunce similarity comparison of coding and noncoding regions between wildtype and delta crza: {t}')\n",
    "\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.scatter([],[], s=50, c = 'purple', edgecolors='black', label = 'Common gene')\n",
    "    plt.legend(loc = 'lower right')\n",
    "\n",
    "    #fig1 = plt.gcf()\n",
    "\n",
    "    #fig1.savefig('test.png', dpi=100)\n",
    "    plt.tight_layout\n",
    "\n",
    "    plt.savefig(f'RNA_Seq_{t}_comparison.png')\n",
    "    return(plt.show())\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below takes FIMO results .tsv files and generates df comparing crzA location and difs between af293 & a1163\n",
    "#from fimo_data 11-21-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fimo_data(path):\n",
    "    \n",
    "    af293_names = []\n",
    "    a1163_names = []\n",
    "\n",
    "\n",
    "    number_dif = []\n",
    "    location_dif = []\n",
    "    \n",
    "    os.chdir(path)\n",
    "    for tsv_file in os.listdir():\n",
    "        if '.tsv' in tsv_file:\n",
    "        \n",
    "            df_tsv = pd.read_csv(tsv_file, sep='\\t').dropna()\n",
    "            \n",
    "            af293_lst = []\n",
    "            a1163_lst = []\n",
    "            \n",
    "            if 'sequence_name' not in df_tsv.columns:\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                seq_names = list(df_tsv['sequence_name'].unique())\n",
    "                \n",
    "                if seq_names == []:\n",
    "                    continue \n",
    "\n",
    "                df_test = pd.read_csv(tsv_file, sep='\\t').dropna()\n",
    "\n",
    "                for i in seq_names:\n",
    "                    if 'AFUA' in i:\n",
    "                        #af293_names.append(i)\n",
    "                        af293_names.append(i)\n",
    "\n",
    "                        af293_df = df_test[df_test['sequence_name'].isin(af293_names)]\n",
    "                        af293_start = list(af293_df['start'])\n",
    "                        af293_stop = list(af293_df['stop'])\n",
    "\n",
    "                        for i in af293_start:\n",
    "                            af293_lst.append(i)\n",
    "                        for i in af293_stop:\n",
    "                            af293_lst.append(i)\n",
    "\n",
    "                    else:\n",
    "                        #a1163_names.append(i)\n",
    "                        a1163_names.append(i)\n",
    "\n",
    "                        a1163_df = df_test[df_test['sequence_name'].isin(a1163_names)]\n",
    "                        a1163_start = list(a1163_df['start'])\n",
    "                        a1163_stop = list(a1163_df['stop'])  \n",
    "\n",
    "                        for i in a1163_start:\n",
    "                            a1163_lst.append(i)\n",
    "                        for i in a1163_stop:\n",
    "                            a1163_lst.append(i)\n",
    "                            \n",
    "                    if len(seq_names) != 2:\n",
    "                        for i in seq_names:\n",
    "                            if 'AFUA' in i:\n",
    "                                a1163_names.append('None')\n",
    "                            if 'AFUB' in i:\n",
    "                                af293_names.append('None')\n",
    "\n",
    "                af293_lst.sort()\n",
    "                a1163_lst.sort()\n",
    "\n",
    "                if len(af293_lst) == len(a1163_lst):\n",
    "                    number_dif.append(False)\n",
    "                else:\n",
    "                    number_dif.append(True)\n",
    "\n",
    "\n",
    "                if af293_lst == a1163_lst:\n",
    "                    location_dif.append(False)\n",
    "                else:\n",
    "                    location_dif.append(True)\n",
    "    \n",
    "    print(f'len of af293_names: {len(af293_names)}')\n",
    "    print(f'len of a1163_names: {len(a1163_names)}')\n",
    "    print(f'len of nums dif: {len(number_dif)}')\n",
    "    print(f'len of location dif: {len(location_dif)}')\n",
    "\n",
    "    cols = 'af293_name a1163_name Differences_in_number_of_crza_sites Differencces_in_crza_site_location'.split()\n",
    "    df_final = pd.DataFrame(columns=cols)\n",
    "\n",
    "    df_final['af293_name'] = af293_names\n",
    "    df_final['a1163_name'] = a1163_names\n",
    "    df_final['Differences_in_number_of_crza_sites'] = number_dif\n",
    "    df_final['Differencces_in_crza_site_location'] = location_dif\n",
    "    \n",
    "\n",
    "    return(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following generate a violin. plot for dn/ds analysis from results excel sheet, I give an example dir as well\n",
    "#From LTR_for_codeml_and_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/alecbrown/Desktop/Rokas_Lab/Genomes_paper_1/dnds_results/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(16,9), dpi=120)\n",
    "\n",
    "ax = sns.violinplot(data = [data_no_outlier, gdov_data], palette = ['cyan', 'coral'])\n",
    "ax.set_ylabel('dN/dS')\n",
    "#ax.set_xlabel('Group')\n",
    "ax.set_xticklabels(['Across Phylogeny','Genetic Determinants of Virulence'])\n",
    "\n",
    "plt.legend(title='Average dN/dS', loc='upper right', labels=['A.P dN/dS average is: 0.189', 'G.D.O.V dN/dS average is: 0.147'])\n",
    "\n",
    "plt.tight_layout\n",
    "\n",
    "plt.savefig('dn_ds_coding_average.png')          \n",
    "\n",
    "#plt.savefig(ax)\n",
    "plt.show(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below was the start of reformating codeml ctl files from a sample file\n",
    "#This and many other reformatting projects can be found orthofinder_make_fasta_10_29_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdr('/Users/alecbrown/Desktop/Rokas_Lab/Genomes_paper_1/fasta/cds/cds_nt_10_29_20_reformat/')\n",
    "for files in os.listdir():\n",
    "    \n",
    "    for i in file_head:\n",
    "        if f'{str(i)}_fasta_cds.txt.pml' in files:\n",
    "\n",
    "            with open('ctl_template.txt', 'r') as f, open(f'{i}.ctl', 'w') as nf:\n",
    "                for line in f:\n",
    "                    if 'seqfile' in line:\n",
    "                        new_line1 = line.replace('replace_me', f'{i}.pml')\n",
    "                        nf.write(new_line1)\n",
    "                    if 'outfile =' in line:\n",
    "                        new_line = line.replace('replace_me', f'{i}_result.txt')\n",
    "                        nf.write(new_line)\n",
    "                    if 'replace_me' in line:\n",
    "                        continue\n",
    "                    else:\n",
    "                        nf.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make ctl files for au_rejected \n",
    "os.chdir('/Users/alecbrown/Desktop/Rokas_Lab/Genomes_paper_1/fasta/cds/codeml_branch_au_rejected_1_15_20/')\n",
    "for i in os.listdir():\n",
    "    \n",
    "    if '.pml' in i:\n",
    "        a,b = i.split('.')\n",
    "        #if f'{str(i)}.pml' in files:\n",
    "\n",
    "        with open('ctl_template.txt', 'r') as f, open(f'{a}.ctl', 'w') as nf:\n",
    "            for line in f:\n",
    "                if 'seqfile' in line:\n",
    "                    new_line1 = line.replace('replace_me', f'{a}.pml')\n",
    "                    nf.write(new_line1)\n",
    "                if 'treefile =' in line:\n",
    "                    new_line = line.replace('replace_me', f'{a}_tree.txt')\n",
    "                    nf.write(new_line)\n",
    "                if 'outfile =' in line:\n",
    "                    new_line = line.replace('replace_me', f'{a}_result.txt')\n",
    "                    nf.write(new_line)\n",
    "                if 'replace_me' in line:\n",
    "                    continue\n",
    "                else:\n",
    "                    nf.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from percent_sim_check_11_5_20:\n",
    "#***use the pandas merge to merge two dataframes***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.merge(df_ana, df_fimo, how='left', left_on=['af293_gene', 'a1163_gene'], right_on = ['af293_name', 'a1163_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reformat fasta files and write new files from reformat_fasta_9_13_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 5215\n",
    "path = '/Users/alecbrown/Desktop/Rokas_Lab/Genomes_paper_1/fasta/upstream_nt_1.5kb/'\n",
    "os.chdir(path)\n",
    "\n",
    "for i in range(0,num):\n",
    "    with open(f'{i}_fasta.txt', 'r') as f, open(f'{i}_fasta_reformat.txt', 'w') as nf:\n",
    "        fasta_id = []\n",
    "        seqs = []\n",
    "        for line in f:\n",
    "            if '>' in line:\n",
    "                if 'AFUA_' in line:\n",
    "                    pattern = re.compile(r'Name=AFUA_[0-9A-Z]+')\n",
    "                    matches = pattern.finditer(line)\n",
    "                                         \n",
    "                    for m in matches:\n",
    "                        fasta_id.append(m.group(0)[5:])\n",
    "                if 'AFUB_' in line:\n",
    "                    pattern = re.compile(r'Name=AFUB_[0-9]+')\n",
    "                    matches = pattern.finditer(line)\n",
    "                                         \n",
    "                    for m in matches:\n",
    "                        fasta_id.append(m.group(0)[5:])\n",
    "                                         \n",
    "                if 'ID=A_oerling' in line:\n",
    "                    pattern = re.compile(r'ID=A_oerling_[A-Z0-9_]+')\n",
    "                    matches = pattern.finditer(line)\n",
    "                                         \n",
    "                    for m in matches:\n",
    "                        fasta_id.append(m.group(0)[3:])\n",
    "                                         \n",
    "                if 'NFIA_' in line:\n",
    "                    pattern = re.compile(r'Name=NFIA_[0-9]+')\n",
    "                    matches = pattern.finditer(line)\n",
    "                                         \n",
    "                    for m in matches:\n",
    "                        fasta_id.append(m.group(0)[5:])\n",
    "                                         \n",
    "                if 'ALT_' in line:\n",
    "                    pattern = re.compile(r'Name=ALT_[0-9]+')\n",
    "                    matches = pattern.finditer(line)\n",
    "                                         \n",
    "                    for m in matches:\n",
    "                        fasta_id.append(m.group(0)[5:])\n",
    "                            \n",
    "                if '.g' in line:\n",
    "                    pattern = re.compile(r'.g[0-9]+')\n",
    "                    matches = pattern.finditer(line)\n",
    "                                         \n",
    "                    for m in matches:\n",
    "                        fasta_id.append(m.group(0)[1:])\n",
    "                                         \n",
    "                if 'P174DRAFT' in line:\n",
    "                    pattern = re.compile(r'Name=P174DRAFT_[0-9]+')\n",
    "                    matches = pattern.finditer(line)\n",
    "                                         \n",
    "                    for m in matches:\n",
    "                        fasta_id.append(m.group(0)[5:])\n",
    "                                         \n",
    "                if 'AUD_' in line:\n",
    "                    pattern = re.compile(r'Name=AUD_[0-9]+')\n",
    "                    matches = pattern.finditer(line)\n",
    "                                         \n",
    "                    for m in matches:\n",
    "                        fasta_id.append(m.group(0)[5:])\n",
    "                                         \n",
    "                if 'CDV56_' in line:\n",
    "                    pattern = re.compile(r'locus_tag=CDV56_[0-9]+')\n",
    "                    matches = pattern.finditer(line)\n",
    "                                         \n",
    "                    for m in matches:\n",
    "                        fasta_id.append(m.group(0)[10:])\n",
    "                                         \n",
    "                if 'CFD26_' in line:\n",
    "                    pattern = re.compile(r'locus_tag=CFD26_[0-9]+')\n",
    "                    matches = pattern.finditer(line)\n",
    "                                         \n",
    "                    for m in matches:\n",
    "                        fasta_id.append(m.group(0)[10:])\n",
    "                        \n",
    "            else:\n",
    "                seqs.append(line[:-2])\n",
    "                                         \n",
    "            #print(seqs)\n",
    "                #nf.write(line)\n",
    "        #print(len(seqs))\n",
    "        #print('--------BREAK-------')\n",
    "        #print(seqs)\n",
    "        if len(seqs) != len(fasta_id):\n",
    "            print(len(seqs))\n",
    "            print(len(fasta_id))\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            #print(len(seqs))\n",
    "            dct = dict(zip(fasta_id, seqs))\n",
    "            \n",
    "            for k,v in dct.items():\n",
    "                nf.write('>' + k + '\\n')\n",
    "                nf.write(v + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Following 3 scripts for reformating found in reformat_for_AU_test_9_25_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_trees(path, old_tf, new_tf, num):\n",
    "    \n",
    "    os.chdir(path)\n",
    "    \n",
    "    for i in range(0,num):\n",
    "        if f'{str(i)}{old_tf}' not in os.listdir():\n",
    "            continue\n",
    "        with open(f'{str(i)}{old_tf}', 'r') as oldfile, open(f'{str(i)}{new_tf}', 'w') as newfile:\n",
    "            dct = {'Aspergillus_fumigatus_af293':None, 'Aspergillus_fumigatus_a1163':None, \n",
    "                   'Aspergillus_oerlinghausenensis':None, \n",
    "                  'Aspergillus_fischeri':None, 'Aspergillus_lentulus':None, 'Aspergillus_novofumigatus':None, \n",
    "                   'Aspergillus_fumigatiaffinis':None, 'Aspergillus_udagawae':None, 'Aspergillus_turcosus':None, \n",
    "                   'Aspergillus_thermomutatus':None }\n",
    "\n",
    "            for line in oldfile:\n",
    "                if 'AFUA_' in line:\n",
    "                    pattern = re.compile(r'AFUA_[0-9A-Z]+')\n",
    "                    matches = pattern.finditer(line)\n",
    "\n",
    "                    for m in matches:\n",
    "                        dct['Aspergillus_fumigatus_af293'] = m.group(0)\n",
    "\n",
    "                    pattern_2 = re.compile(r'AFUB_[0-9]+')\n",
    "                    matches_2 = pattern_2.finditer(line)\n",
    "\n",
    "                    for m in matches_2:\n",
    "                        dct['Aspergillus_fumigatus_a1163'] = m.group(0)\n",
    "\n",
    "                    pattern_3 = re.compile(r'A_oerling_[0-9A-Z_]+')\n",
    "                    matches_3 = pattern_3.finditer(line)\n",
    "\n",
    "                    for m in matches_3:\n",
    "                        dct['Aspergillus_oerlinghausenensis'] = m.group(0)\n",
    "\n",
    "                    pattern_4 = re.compile(r'NFIA_[0-9]+')\n",
    "                    matches_4 = pattern_4.finditer(line)\n",
    "\n",
    "                    for m in matches_4:\n",
    "                        dct['Aspergillus_fischeri'] = m.group(0)\n",
    "\n",
    "                    pattern_5 = re.compile(r'ALT_[0-9]+')\n",
    "                    matches_5 = pattern_5.finditer(line)\n",
    "\n",
    "                    for m in matches_5:\n",
    "                        dct['Aspergillus_lentulus'] = m.group(0)\n",
    "\n",
    "\n",
    "                    pattern_7 = re.compile(r'P174DRAFT_[0-9]+')\n",
    "                    matches_7 = pattern_7.finditer(line)\n",
    "\n",
    "                    for m in matches_7:\n",
    "                        dct['Aspergillus_novofumigatus'] = m.group(0)\n",
    "\n",
    "                    pattern_8 = re.compile(r'AUD_[0-9]+')\n",
    "                    matches_8 = pattern_8.finditer(line)\n",
    "\n",
    "                    for m in matches_8:\n",
    "                        dct['Aspergillus_udagawae'] = m.group(0)\n",
    "\n",
    "                    pattern_9 = re.compile(r'CDV56_[0-9]+')\n",
    "                    matches_9 = pattern_9.finditer(line)\n",
    "\n",
    "                    for m in matches_9:\n",
    "                        dct['Aspergillus_thermomutatus'] = m.group(0)\n",
    "\n",
    "                    pattern_10 = re.compile(r'CFD26_[0-9]+')\n",
    "                    matches_10 = pattern_10.finditer(line)\n",
    "\n",
    "                    for m in matches_10:\n",
    "                        dct['Aspergillus_turcosus'] = m.group(0)\n",
    "                        \n",
    "                    pattern_11 = re.compile(r'\\([g0-9]+')\n",
    "                    matches_11 = pattern_11.finditer(line)\n",
    "\n",
    "                    for m in matches_11:\n",
    "                        dct['Aspergillus_fumigatiaffinis'] = m.group(0)[1:]\n",
    "                        \n",
    "                    pattern_12 = re.compile(r',g[0-9]+')\n",
    "                    matches_12 = pattern_12.finditer(line)\n",
    "\n",
    "                    for m in matches_12:\n",
    "                        dct['Aspergillus_fumigatiaffinis'] = m.group(0)[1:]\n",
    "\n",
    "                    new_line = line\n",
    "                    for k,v in dct.items():\n",
    "                        if v == None:\n",
    "                            continue\n",
    "                        if v in line:\n",
    "                            new_line = new_line.replace(v,k) #need a way to save the line each time we do this\n",
    "                    newfile.write(new_line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_mafft(path, old_tf, new_tf, num):\n",
    "    \n",
    "    os.chdir(path)\n",
    "    \n",
    "    for i in range(0,num):\n",
    "        if f'{str(i)}{old_tf}' not in os.listdir():\n",
    "            continue\n",
    "        with open(f'{str(i)}{old_tf}', 'r') as oldfile, open(f'{str(i)}{new_tf}', 'w') as newfile:\n",
    "            fasta_id = []\n",
    "            seqs = []\n",
    "            for line in oldfile:\n",
    "                if '>' in line:\n",
    "                    if 'AFUA_' in line:\n",
    "                        new_line = line.replace(line, 'Aspergillus_fumigatus_af293')\n",
    "                        newfile.write('>'+ new_line + '\\n')\n",
    "                    if 'AFUB_' in line:\n",
    "                        new_line = line.replace(line, 'Aspergillus_fumigatus_a1163')\n",
    "                        newfile.write('>'+ new_line + '\\n')\n",
    "                    if 'A_oerling' in line:\n",
    "                        new_line = line.replace(line, 'Aspergillus_oerlinghausenensis')\n",
    "                        newfile.write('>'+ new_line + '\\n')   \n",
    "                    if 'NFIA_' in line:\n",
    "                        new_line = line.replace(line, 'Aspergillus_fischeri')\n",
    "                        newfile.write('>'+ new_line + '\\n')\n",
    "                    if 'ALT_' in line:\n",
    "                        new_line = line.replace(line, 'Aspergillus_lentulus')\n",
    "                        newfile.write('>'+ new_line + '\\n') \n",
    "                    if '>g' in line:\n",
    "                        new_line = line.replace(line, 'Aspergillus_fumigatiaffinis')\n",
    "                        newfile.write('>'+ new_line + '\\n') \n",
    "                    if 'P174DRAFT' in line:\n",
    "                        new_line = line.replace(line, 'Aspergillus_novofumigatus')\n",
    "                        newfile.write('>'+ new_line + '\\n') \n",
    "                    if 'AUD_' in line:\n",
    "                        new_line = line.replace(line, 'Aspergillus_udagawae')\n",
    "                        newfile.write('>'+ new_line + '\\n') \n",
    "                    if 'CDV56_' in line:\n",
    "                        new_line = line.replace(line, 'Aspergillus_thermomutatus')\n",
    "                        newfile.write('>'+ new_line + '\\n') \n",
    "                    if 'CFD26_' in line:\n",
    "                        new_line = line.replace(line, 'Aspergillus_turcosus')\n",
    "                        newfile.write('>'+ new_line + '\\n') \n",
    "\n",
    "                else:\n",
    "                    newfile.write(line[:-2]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_files_for_au(path, handle, newfile, num):\n",
    "    \n",
    "    os.chdir(path)\n",
    "    \n",
    "    for i in range(0,num):\n",
    "        if f'{str(i)}{handle}' not in os.listdir():\n",
    "            continue\n",
    "        else:\n",
    "            with open(f'{str(i)}{handle}', 'r') as oldfile, open(f'{str(i)}{newfile}', 'w') as nf:\n",
    "                for line in oldfile:\n",
    "                    nf.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making some fasta files for af293 and a1163\n",
    "\n",
    "def make_some_fastas(path, num):\n",
    "\n",
    "    #num = 5215\n",
    "    #path = '/Users/alecbrown/Desktop/Rokas_Lab/Genomes_paper_1/fasta/upstream_nt_1.5kb/'\n",
    "    os.chdir(path)\n",
    "\n",
    "    for i in range(0,num):\n",
    "        with open(f'{i}_upstream.txt', 'r') as f, open(f'{i}_fasta.txt', 'w') as nf:\n",
    "            fasta_id = []\n",
    "            seqs = []\n",
    "            for line in f:\n",
    "                if '>' in line:\n",
    "                    if 'AFUA_' in line:\n",
    "                        pattern = re.compile(r'Name=AFUA_[0-9A-Z]+')\n",
    "                        matches = pattern.finditer(line)\n",
    "\n",
    "                        for m in matches:\n",
    "                            fasta_id.append(m.group(0)[5:])\n",
    "                    if 'AFUB_' in line:\n",
    "                        pattern = re.compile(r'Name=AFUB_[0-9]+')\n",
    "                        matches = pattern.finditer(line)\n",
    "\n",
    "                        for m in matches:\n",
    "                            fasta_id.append(m.group(0)[5:])\n",
    "\n",
    "                else:\n",
    "                    seqs.append(line[:-2])\n",
    "\n",
    "            if len(seqs) != len(fasta_id):\n",
    "                print(len(seqs))\n",
    "                print(len(fasta_id))\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                #print(len(seqs))\n",
    "                dct = dict(zip(fasta_id, seqs))\n",
    "\n",
    "                for k,v in dct.items():\n",
    "                    nf.write('>' + k + '\\n')\n",
    "                    nf.write(v + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sequence logos - found in make_logos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#More reformatting protein ids and gene ids in orthofinder_make_fasta_10_29_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following gives a column by column snps between sequences, MUCH MORE in snps_columns notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = []\n",
    "snps = []\n",
    "remove_commas = []\n",
    "\n",
    "for i in range(len(fumigatus_seq)):\n",
    "    fum_cols = ','.join(fumigatus_seq[i])\n",
    "    fis_cols = ','.join(fischeri_seq[i])\n",
    "    \n",
    "    if len(fumigatus_seq[i]) <= len(fischeri_seq[i]):\n",
    "        index = len(','.join(fumigatus_seq[i]))\n",
    "    else:\n",
    "        index = len(','.join(fischeri_seq[i]))\n",
    "        \n",
    "    \n",
    "    for j in range(index):\n",
    "        if (fum_cols[j] and fis_cols[j]) == ',':\n",
    "            remove_commas.append('')\n",
    "        \n",
    "        else:\n",
    "            if (fum_cols[j] == fis_cols[j]) and fum_cols[j] != ',':\n",
    "                nums.append(1) \n",
    "            else:\n",
    "                nums.append(0)\n",
    "      \n",
    "        \n",
    "    snps.append(nums)\n",
    "    nums = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of how to copy files from one dir to another \n",
    "import shutil\n",
    "for i in os.listdir():\n",
    "    if i in handle:\n",
    "        shutil.copy(i, '/Users/alecbrown/Desktop/Rokas_Lab/Genomes_paper_1/Trees/Noncoding_500bp/RF_AU_rejected/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get robinsons foulds results from phykikt into a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rf_results(path):\n",
    "    name, rf, rf_n = [], [], []\n",
    "    os.chdir(path)\n",
    "    for i in os.listdir():\n",
    "        if \"result.txt\" in i:\n",
    "            name.append(i)\n",
    "            with open(i, 'r') as f:\n",
    "                for line in f:\n",
    "                    nl = line.strip()\n",
    "                    nl = nl.replace('\\t', '_')\n",
    "                    a,b = nl.split('_')\n",
    "                    rf.append(int(a))\n",
    "                    rf_n.append(float(b))\n",
    "                    \n",
    "    heads = 'file_name rf rf_normalized'.split()\n",
    "    df = pd.DataFrame(columns=heads)\n",
    "    df['file_name'], df['rf'], df['rf_normalized'] = name, rf, rf_n\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-11-20: The following makes a dct for mafft file with file handle as key and af293 gene name as value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dct(path):\n",
    "    \n",
    "    os.chdir(path)\n",
    "    dct = {}\n",
    "    \n",
    "    for i in os.listdir():\n",
    "        if '.txt' in i:\n",
    "            a,b,c = i.split('_')\n",
    "            \n",
    "            with open(i, 'r') as f:\n",
    "                for line in f:\n",
    "                    if '>' in line and 'AFUA' in line:\n",
    "                        z = line[1:-1]\n",
    "                        \n",
    "        dct[a] = z\n",
    "        \n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script to seperate txt file by line, by word, by character\n",
    "\n",
    "import os\n",
    "\n",
    "def wc(file_path):\n",
    "    \"\"\"Takes an absolute file path/name, calculates the number of\n",
    "       lines/words/chars, and returns a string of these numbers + file, e.g.:\n",
    "       3 12 60 /tmp/somefile\n",
    "       (both tabs and spaces are allowed as separator)\"\"\"\n",
    "\n",
    "        with open(file_path, 'r') as f:\n",
    "            content = f.read() #takes files and places into txt in python \n",
    "            num_lines = len(content.splitlines()) # split text by newline\n",
    "            num_words = len(content.split()) #split text by empty space to get words\n",
    "            num_chars = len(context)\n",
    "            \n",
    "            \n",
    "    return (f'{num_lines}\\t{num_words}\\t{num_chars}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reformat pml files so that they are numbered instead\n",
    "\n",
    "def reformat_pml(path, old_tf, new_tf, num):\n",
    "    \n",
    "    os.chdir(path)\n",
    "    \n",
    "    for i in range(0,num):\n",
    "        if f'{str(i)}{old_tf}' not in os.listdir():\n",
    "            continue\n",
    "        with open(f'{str(i)}{old_tf}', 'r') as oldfile, open(f'{str(i)}{new_tf}', 'w') as newfile:\n",
    "            fasta_id = []\n",
    "            seqs = []\n",
    "            for line in oldfile:\n",
    "                if 'AFUA_' in line:\n",
    "                    new_line = line.replace(line, '1')\n",
    "                    newfile.write(new_line + '\\n')\n",
    "                    continue\n",
    "                if 'AFUB_' in line:\n",
    "                    new_line = line.replace(line, '2')\n",
    "                    newfile.write(new_line + '\\n')\n",
    "                    continue\n",
    "                if 'CBS' in line:\n",
    "                    new_line = line.replace(line, '3')\n",
    "                    newfile.write(new_line + '\\n')\n",
    "                    continue\n",
    "                if 'NFIA_' in line:\n",
    "                    new_line = line.replace(line, '4')\n",
    "                    newfile.write(new_line + '\\n')\n",
    "                    continue\n",
    "                if 'ALT_' in line:\n",
    "                    new_line = line.replace(line, '5')\n",
    "                    newfile.write(new_line + '\\n') \n",
    "                    continue\n",
    "                if 'CNMC' in line:\n",
    "                    new_line = line.replace(line, '6')\n",
    "                    newfile.write(new_line + '\\n') \n",
    "                    continue\n",
    "                if 'P174DRAFT' in line:\n",
    "                    new_line = line.replace(line, '7')\n",
    "                    newfile.write(new_line + '\\n') \n",
    "                    continue\n",
    "                if 'AUD_' in line:\n",
    "                    new_line = line.replace(line, '8')\n",
    "                    newfile.write(new_line + '\\n') \n",
    "                    continue\n",
    "                if 'CDV56_' in line:\n",
    "                    new_line = line.replace(line, '9')\n",
    "                    newfile.write(new_line + '\\n') \n",
    "                    continue\n",
    "                if 'CFD26_' in line:\n",
    "                    new_line = line.replace(line, '10')\n",
    "                    newfile.write(new_line + '\\n') \n",
    "                    continue\n",
    "\n",
    "                else:\n",
    "                    newfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#script to get codmel result into a df from branch test\n",
    "def get_codeml_results(path):\n",
    "    \n",
    "    af293_name = []\n",
    "    a1163_name = []\n",
    "    lnl = []\n",
    "    af293_omega = []\n",
    "    a1163_omega = []\n",
    "    fumigatus_omega = []\n",
    "    \n",
    "    os.chdir(path)\n",
    "    \n",
    "    for file in os.listdir():\n",
    "        if '.txt' in file:\n",
    "            with open(file, 'r') as f:\n",
    "                for line in f:\n",
    "                    if '#1:' in line and 'AFUA':\n",
    "                        af293_name.append(line[3:].strip()) \n",
    "                \n",
    "                    if '#2:' in line and 'AFUB':\n",
    "                        a1163_name.append(line[3:].strip()) \n",
    "                        \n",
    "                    if 'lnL' in line:\n",
    "                        total = line.split()\n",
    "                        lnl.append(float(total[4]))\n",
    "                        \n",
    "                    if '17..1' in line and '0.' in line:\n",
    "                        total = line.split()\n",
    "                        af293_omega.append(float(total[4]))\n",
    "    \n",
    "                    if '17..2' in line and '0.' in line:\n",
    "                        total = line.split()\n",
    "                        a1163_omega.append(float(total[4]))\n",
    "                    \n",
    "                    if '16..17' in line and '0.' in line:\n",
    "                        total = line.split()\n",
    "                        fumigatus_omega.append(float(total[4]))\n",
    "                        \n",
    "        if len(af293_name) != len(af293_omega):\n",
    "            af293_omega.append()\n",
    "            break\n",
    "    \n",
    "    \n",
    "    column_name = 'af293_name a1163_name af293_omega a1163_omega fumigatus_omega lnl_value'.split()\n",
    "\n",
    "    df = pd.DataFrame(columns=column_name)\n",
    "    \n",
    "    df['af293_name'] = af293_name\n",
    "    df['a1163_name'] = a1163_name\n",
    "    df['af293_omega'] = af293_omega\n",
    "    df['a1163_omega'] = a1163_omega\n",
    "    df['fumigatus_omega'] = fumigatus_omega\n",
    "    df['lnl_value'] = lnl\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hyphy_batch(path):\n",
    "    \n",
    "    os.chdir(path)\n",
    "    for i in os.listdir():\n",
    "\n",
    "        if '_pml.txt' in i:\n",
    "            a,b = i.split('_')\n",
    "            #if f'{str(i)}.pml' in files:\n",
    "\n",
    "            with open('template_hyphy.bf', 'r') as f, open(f'{a}_hyphy.bf', 'w') as nf:\n",
    "                for line in f:\n",
    "                    if 'replace_me_pml' in line:\n",
    "                        new_line1 = line.replace('replace_me_pml', f'{path}{a}_pml.txt')\n",
    "                        nf.write(new_line1)\n",
    "                    if 'replace_me_fasta' in line:\n",
    "                        new_line = line.replace('replace_me_fasta', f'{path}{a}_fasta.txt')\n",
    "                        nf.write(new_line)\n",
    "                    if 'replace_me' in line:\n",
    "                        continue\n",
    "                    else:\n",
    "                        nf.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#required externally made dct, from hyphy noncoding au rejected \n",
    "def au_rejected_make_hyphy_batch(path):\n",
    "    \n",
    "    os.chdir(path)\n",
    "    for i in os.listdir():\n",
    "\n",
    "        if '_pml.txt' in i:\n",
    "            a,b = i.split('_')\n",
    "            #if f'{str(i)}.pml' in files:\n",
    "\n",
    "            with open('template_hyphy.bf', 'r') as f, open(f'{a}_hyphy.bf', 'w') as nf:\n",
    "                for line in f:\n",
    "                    if 'replace_me_pml' in line:\n",
    "                        new_line1 = line.replace('replace_me_pml', f'{path}{a}_pml.txt')\n",
    "                        nf.write(new_line1)\n",
    "                    if 'replace_me_tree' in line:\n",
    "                        new_line1 = line.replace('replace_me_tree', f'{path}{a}_tree.txt')\n",
    "                        nf.write(new_line1)\n",
    "                    if 'replace_me_node' in line:\n",
    "                        if i in nodes_dct.keys():\n",
    "                            \n",
    "                            new_line1 = line.replace('replace_me_node', nodes_dct[i])\n",
    "                            nf.write(new_line1)\n",
    "                    if 'replace_me_fasta' in line:\n",
    "                        new_line = line.replace('replace_me_fasta', f'{path}{a}_fasta.txt')\n",
    "                        nf.write(new_line)\n",
    "                    if 'replace_me' in line:\n",
    "                        continue\n",
    "                    else:\n",
    "                        nf.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyphy_results(path):\n",
    "    \n",
    "    file_name = []\n",
    "    lnl_null = []\n",
    "    lnl_alt = []\n",
    "    lrt = []\n",
    "    p_value = []\n",
    "    zeta0_null = []\n",
    "    zeta1_null = []\n",
    "    zeta0_alt = []\n",
    "    zeta1_alt = []\n",
    "    zeta2_alt = []\n",
    "    \n",
    "    os.chdir(path)\n",
    "    \n",
    "    for file in os.listdir():\n",
    "        if '.result' in file:\n",
    "            l = []\n",
    "            s = []\n",
    "            with open(file, 'r') as f:\n",
    "                content = f.read()\n",
    "                if 'zeta0' not in content:\n",
    "                    continue\n",
    "                else:\n",
    "                    file_name.append(file)\n",
    "                    \n",
    "                    for line in content.splitlines():\n",
    "                        if 'Lk' in line:\n",
    "                            total = line.split()\n",
    "                            lnl_null.append(float(total[3]))\n",
    "                            lnl_alt.append(float(total[7]))\n",
    "                        if 'LRT' in line and 'p' not in line:\n",
    "                            total = line.split()\n",
    "                            lrt.append(float(total[2]))\n",
    "                        if 'LRT' in line and 'p' in line:\n",
    "                            t = line.split()\n",
    "                            p_value.append(float(t[3]))\n",
    "                        if 'zeta0' in line:\n",
    "                            z0 = (line.strip().split())\n",
    "                            l.append(float(z0[-1]))\n",
    "                        if 'zeta1' in line:\n",
    "                            z1 = (line.strip().split())\n",
    "                            s.append(float(z1[-1]))\n",
    "                        if 'zeta2' in line:\n",
    "                            total = line.split()\n",
    "                            zeta2_alt.append(float(total[-1]))\n",
    "                \n",
    "                zeta0_null.append(l[0])\n",
    "                zeta0_alt.append(l[-1])\n",
    "                zeta1_null.append(s[0])\n",
    "                zeta1_alt.append(s[-1])\n",
    "        \n",
    "    print(len(file_name))\n",
    "    print(len(lnl_alt))\n",
    "    column_name = 'file_name lnl_null lnl_alt lrt p_value zeta0_null zeta1_null zeta0_alt zeta1_alt zeta2_alt'.split()\n",
    "\n",
    "    df = pd.DataFrame(columns=column_name)\n",
    "    \n",
    "    df['file_name'] = file_name\n",
    "    df['lnl_null'] = lnl_null\n",
    "    df['lnl_alt'] = lnl_alt\n",
    "    df['lrt'] = lrt\n",
    "    df['p_value'] = p_value\n",
    "    df['zeta0_null'] = zeta0_null\n",
    "    df['zeta1_null'] = zeta1_null\n",
    "    df['zeta0_alt'] = zeta0_alt\n",
    "    df['zeta1_alt'] = zeta1_alt\n",
    "    df['zeta2_alt'] = zeta2_alt\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following was used to get synteny upstream genes from SCO gene list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for oerl: \n",
    "\n",
    "dct_num_key= {}\n",
    "dct_num_values = {}\n",
    "with open('A_oerlinghausenensis_CBS139183_genomic.gff', 'r') as f:\n",
    "    c = 0\n",
    "    for line in f:\n",
    "        if 'gene' in line:\n",
    "            x = line.split(';')\n",
    "            #print(x)\n",
    "            for data in x:\n",
    "                if 'ID=' in data and 'mRNA' not in data:\n",
    "                    z = data.split('\\t')\n",
    "                    if 'ID=NODE' in z[8]:\n",
    "                        continue\n",
    "                    else:\n",
    "                        dct_num_values[z[8]] = c\n",
    "                        dct_num_key[c] = z[8]\n",
    "                        c +=1\n",
    "                        \n",
    "#for fischeri\n",
    "dct_num_key= {}\n",
    "dct_num_values = {}\n",
    "with open('A_fischeri_NRRL181_genomic.gff', 'r') as f:\n",
    "    c = 0\n",
    "    for line in f:\n",
    "        if 'gene' in line:\n",
    "            sections = line.split('\\t')\n",
    "            if 'gene' in sections[2] and 'NFIA_' in sections[8]:\n",
    "                sections_2 = sections[8].split(';')\n",
    "                dct_num_key[c] = sections_2[2][5:]\n",
    "                dct_num_values[sections_2[2][5:]] = c\n",
    "                c +=1\n",
    "                \n",
    "#for lentulus\n",
    "dct_num_key= {}\n",
    "dct_num_values = {}\n",
    "with open('A_lentulus_IFM54703_genomic.gff', 'r') as f:\n",
    "    c = 0\n",
    "    for line in f:\n",
    "        if 'gene' in line:\n",
    "            sections = line.split('\\t')\n",
    "            if 'gene' in sections[2] and 'ALT_' in sections[8]:\n",
    "                sections_2 = sections[8].split(';')\n",
    "                dct_num_key[c] = sections_2[1][5:]\n",
    "                dct_num_values[sections_2[1][5:]] = c\n",
    "                c +=1\n",
    "                \n",
    "#novo\n",
    "dct_num_key= {}\n",
    "dct_num_values = {}\n",
    "with open('A_novofumigatus_IBT16806_genomic.gff', 'r') as f:\n",
    "    c = 0\n",
    "    for line in f:\n",
    "        if 'gene' in line:\n",
    "            sections = line.split('\\t')\n",
    "            if 'gene' in sections[2] and 'P174DRAFT_' in sections[8]:\n",
    "                sections_2 = sections[8].split(';')\n",
    "                dct_num_key[c] = sections_2[2][5:]\n",
    "                dct_num_values[sections_2[2][5:]] = c\n",
    "                c +=1\n",
    "                \n",
    "#udagawae\n",
    "dct_num_key= {}\n",
    "dct_num_values = {}\n",
    "with open('A_udagawae_IFM46973_genomic.gff', 'r') as f:\n",
    "    c = 0\n",
    "    for line in f:\n",
    "        if 'gene' in line:\n",
    "            sections = line.split('\\t')\n",
    "            if 'gene' in sections[2] and 'AUD_' in sections[8]:\n",
    "                sections_2 = sections[8].split(';')\n",
    "                dct_num_key[c] = sections_2[1][5:]\n",
    "                dct_num_values[sections_2[1][5:]] = c\n",
    "                c +=1\n",
    "                \n",
    "#Let's try again for thermomutatus\n",
    "dct_num_key= {}\n",
    "dct_num_values = {}\n",
    "with open('A_thermomutatus_HMRAF39_genomic.gff', 'r') as f:\n",
    "    c = 0\n",
    "    for line in f:\n",
    "        if 'gene' in line:\n",
    "            sections = line.split('\\t')\n",
    "            if 'gene' in sections[2]:\n",
    "                sections_2 = sections[8].split(';')\n",
    "                for info in sections_2:\n",
    "                    if 'CDV56' in sections_2[2]:\n",
    "                        if sections_2[2][5:] in dct_num_key.values():\n",
    "                            continue\n",
    "                        else:\n",
    "                            dct_num_key[c] = sections_2[2][5:]\n",
    "                            dct_num_values[sections_2[2][5:]] = c\n",
    "                            c +=1\n",
    "                    else:\n",
    "                        if 'CDV56' in sections_2[7]:\n",
    "                            if sections_2[7][10:] in dct_num_key.values():\n",
    "                                continue\n",
    "                            else:\n",
    "                                dct_num_key[c] = sections_2[7][10:]\n",
    "                                dct_num_values[sections_2[7][10:]] = c\n",
    "                                c +=1\n",
    "                                \n",
    "#turcosus\n",
    "dct_num_key= {}\n",
    "dct_num_values = {}\n",
    "with open('A_turcosus_HMRAF1038_genomic.gff', 'r') as f:\n",
    "    c = 0\n",
    "    for line in f:\n",
    "        if 'gene' in line:\n",
    "            sections = line.split('\\t')\n",
    "            if 'gene' in sections[2]:\n",
    "                sections_2 = sections[8].split(';')\n",
    "                for info in sections_2:\n",
    "                    if 'CFD26' in sections_2[2]:\n",
    "                        if sections_2[2][5:-1] in dct_num_key.values():\n",
    "                            continue\n",
    "                        else:\n",
    "                            dct_num_key[c] = sections_2[1][5:-1]\n",
    "                            dct_num_values[sections_2[1][5:-1]] = c\n",
    "                            c +=1\n",
    "                    else:\n",
    "                        if 'CFD26' in sections_2[4]:\n",
    "                            if sections_2[4][10:-1] in dct_num_key.values():\n",
    "                                continue\n",
    "                            else:\n",
    "                                dct_num_key[c] = sections_2[4][10:-1]\n",
    "                                dct_num_values[sections_2[4][10:-1]] = c\n",
    "                                c +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percent_from_mafft(path):\n",
    "    \n",
    "    ids = []\n",
    "    percent = []\n",
    "    legnth = []\n",
    "    \n",
    "    os.chdir(path)\n",
    "    \n",
    "    for i in os.listdir():\n",
    "        if '.txt' in i:\n",
    "            with open(i, 'r') as f:\n",
    "                #print(i)\n",
    "                content = f.read()\n",
    "                t = content.strip().split('>')\n",
    "                \n",
    "                af293 = t[1][13:]\n",
    "                a1163 = t[2][12:]\n",
    "                oerl = t[3][26:]\n",
    "                fischeri = t[4][12:]\n",
    "                lentulus = t[5][9:]\n",
    "                affinis = t[6][6:]\n",
    "                novo = t[7][17:]\n",
    "                udagawae = t[8][9:]\n",
    "                turcosus = t[9][13:]\n",
    "                thermo = t[10][13:]\n",
    "\n",
    "                count = 0\n",
    "                for i in af293:\n",
    "                    if i != '-':\n",
    "                        count += 1\n",
    "                for i in a1163:\n",
    "                    if i != '-':\n",
    "                        count += 1\n",
    "                for i in oerl:\n",
    "                    if i != '-':\n",
    "                        count += 1\n",
    "                for i in fischeri:\n",
    "                    if i != '-':\n",
    "                        count += 1\n",
    "                for i in lentulus:\n",
    "                    if i != '-':\n",
    "                        count += 1\n",
    "                for i in affinis:\n",
    "                    if i != '-':\n",
    "                        count += 1\n",
    "                for i in novo:\n",
    "                    if i != '-':\n",
    "                        count += 1\n",
    "                for i in udagawae:\n",
    "                    if i != '-':\n",
    "                        count += 1\n",
    "                for i in turcosus:\n",
    "                    if i != '-':\n",
    "                        count += 1\n",
    "                for i in thermo:\n",
    "                    if i != '-':\n",
    "                        count += 1\n",
    "                        \n",
    "                ids.append(t[1][:12])\n",
    "                legnth.append(len(af293))\n",
    "                percent.append(count/(len(af293)*10))\n",
    "                \n",
    "    names = 'gene legnth percent'.split()\n",
    "\n",
    "    df = pd.DataFrame(columns=names)\n",
    "\n",
    "    df['gene'] = ids\n",
    "    df['legnth'] = legnth\n",
    "    df['percent'] = percent\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scripts to get column by column similarity \n",
    "def get_snps(path):\n",
    "    \n",
    "    gene_1_names = []\n",
    "    gene_2_names = []\n",
    "    snps_lst = []\n",
    "    \n",
    "    os.chdir(path)\n",
    "    \n",
    "    for file in os.listdir():\n",
    "        if '.txt' in file:\n",
    "            with open(file, 'r') as f:\n",
    "                column_stats = []\n",
    "                \n",
    "                content = f.read()\n",
    "                content_split = content.split('\\n')\n",
    "\n",
    "                gene_1_names.append(content_split[0][1:])\n",
    "                gene_2_names.append(content_split[6][1:])\n",
    "                \n",
    "                seq_1 = content_split[1]\n",
    "                seq_2 = content_split[7]\n",
    "                \n",
    "                seq_1_reverse = seq_1[::-1]\n",
    "                seq_2_reverse = seq_2[::-1]\n",
    "                \n",
    "                if len(seq_1_reverse) <= len(seq_2_reverse):\n",
    "                    len_total = len(seq_1_reverse)\n",
    "                else:\n",
    "                    len_total = len(seq_2_reverse)\n",
    "                    \n",
    "                for i in range(len_total):\n",
    "                    if seq_1_reverse[i] == seq_2_reverse[i]:\n",
    "                        column_stats.append(int(1))\n",
    "                    if seq_1_reverse[i] != seq_2_reverse[i]:\n",
    "                        column_stats.append(int(0))\n",
    "                    else:\n",
    "                        continue\n",
    "                        \n",
    "                snps_lst.append(column_stats)\n",
    "            \n",
    "    column_names = 'af293 fischeri snps'.split()\n",
    "    df = pd.DataFrame(columns=column_names)\n",
    "    \n",
    "    df['af293'] = gene_1_names\n",
    "    df['fischeri'] = gene_2_names\n",
    "    df['snps'] = snps_lst\n",
    "    \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
